{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본적인 라이브러리 호출\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1 import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vocab', 'vocab_size'])\n"
     ]
    }
   ],
   "source": [
    "# 이전에 저장했던 학습에 필요한 디렉터리 설정 및 학습/평가 데이터를 불러온다.\n",
    "\n",
    "DATA_IN_PATH='./data_in/'\n",
    "DATA_OUT_PATH='./data_out/'\n",
    "INPUT_TRAIN_DATA_FILE_NAME='train_input.npy'\n",
    "LABEL_TRAIN_DATA_FILE_NAME='train_label.npy'\n",
    "\n",
    "TEST_INPUT_DATA_FILE_NAME='test_input.npy'\n",
    "\n",
    "DATA_CONFIGS_FILE_NAME='data_configs.json'\n",
    "\n",
    "train_input_data=np.load(open(DATA_IN_PATH+INPUT_TRAIN_DATA_FILE_NAME,'rb'))\n",
    "train_label_data=np.load(open(DATA_IN_PATH+LABEL_TRAIN_DATA_FILE_NAME,'rb'))\n",
    "test_input_data=np.load(open(DATA_IN_PATH+TEST_INPUT_DATA_FILE_NAME,'rb'))\n",
    "\n",
    "with open(DATA_IN_PATH+DATA_CONFIGS_FILE_NAME,'r') as f:\n",
    "    prepro_configs=json.load(f)\n",
    "    print(prepro_configs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 파라미터 변수\n",
    "\n",
    "RNG_SEED=1234\n",
    "BATCH_SIZE=128\n",
    "NUM_EPOCHS=10000\n",
    "VOCAB_SIZE=prepro_configs['vocab_size']\n",
    "EMB_SIZE=128\n",
    "VALID_SPLIT=0.2\n",
    "\n",
    "# 학습 데이터와 검증 데이터를 train_test_split 함수를 활용해 나눈다.\n",
    "train_input, eval_input, train_label, eval_label=train_test_split(train_input_data, train_label_data, test_size=VALID_SPLIT, random_state=RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 학습을 위해 tf.data를 설정한다.\n",
    "\n",
    "def mapping_fn(X, Y=None):\n",
    "    input, label={'x':X},Y\n",
    "    return input,label\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((train_input, train_label))\n",
    "    dataset=dataset.shuffle(buffer_size=len(train_input))\n",
    "    dataset=dataset.batch(BATCH_SIZE)\n",
    "    dataset=dataset.map(mapping_fn)\n",
    "    dataset=dataset.repeat(count=NUM_EPOCHS)\n",
    "    \n",
    "    iterator=dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()\n",
    "\n",
    "def eval_input_fn():\n",
    "    dataset=tf.data.Dataset.from_tensor_slices((input_eval,label_eval))\n",
    "    dataset=dataset.shuffle(buffer_size=len(input_eval))\n",
    "    dataset=dataset.batch(BATCH_SIZE)\n",
    "    dataset=dataset.map(mapping_fn)\n",
    "    \n",
    "    iterator=dataset.make_one_shot_iterator()\n",
    "    \n",
    "    return iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    TRAIN=mode==tf.estimator.ModeKeys.TRAIN\n",
    "    EVAL=mode==tf.estimator.ModeKeys.EVAL\n",
    "    PREDICT=mode==tf.estimator.ModeKeys.PREDICT\n",
    "    \n",
    "    # embedding layer를 선언합니다.\n",
    "    embedding_layer=keras.layers.Embedding(VOCAB_SIZE,EMB_SIZE)(features['x'])\n",
    "    \n",
    "    # embedding layer에 대한 output에 대해 dropout을 취합니다.\n",
    "    dropout_emb=keras.layers.Dropout(rate=0.5)(embedding_layer)\n",
    "    \n",
    "    ## filters=128이고 kernel_size=3,4,5다.\n",
    "    ## 길이가 3, 4, 5인 128개의 다른 필터를 생성한다. 3,4,5 gram의 효과처럼 다양한 각도에서 문장을 보는 효과가 있다.\n",
    "    ## conv1d는 (배치 크기, 길이, 채널)로 입력값을 받는데, 배치 사이즈: 문장 숫자 | 길이: 각 문장의 단어의 개수 | 채널 : 임베딩 출력 차원수임\n",
    "    \n",
    "    conv1=keras.layers.Conv1D(filters=128, kernel_size=3, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "    \n",
    "    pool1=keras.layers.GlobalMaxPool1D()(conv1)\n",
    "    \n",
    "    conv2=keras.layers.Conv1D(filters=128, kernel_size=4, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "    \n",
    "    pool2=keras.layers.GlobalMaxPool1D()(conv2)\n",
    "    \n",
    "    conv3=keras.layers.Conv1D(filters=128, kernel_size=5, padding='valid', activation=tf.nn.relu)(dropout_emb)\n",
    "    \n",
    "    pool3=keras.layers.GlobalMaxPool1D()(conv3)\n",
    "    \n",
    "    # 3,4,5gram 이후 모아주기\n",
    "    concat=keras.layers.concatenate([pool1, pool2, pool3])\n",
    "    \n",
    "    hidden=keras.layers.Dense(250, activation=tf.nn.relu)(concat)\n",
    "    dropout_hidden=keras.layers.Dropout(rate=0.5)(hidden)\n",
    "    logits=keras.layers.Dense(1, name='logits')(dropout_hidden)\n",
    "    logits=tf.squeeze(logits, axis=-1)\n",
    "    \n",
    "    # 최종적으로 학습, 검증, 평가의 단계로 나누어 활용\n",
    "    \n",
    "    if PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions={'prob':tf.nn.sigmoid(logits)})\n",
    "    \n",
    "    loss=tf.losses.sigmoid_cross_entropy(labels, logits)\n",
    "    \n",
    "    if EVAL:\n",
    "        pred=tf.nn.sigmoid(logits)\n",
    "        accuracy=tf.metrics.accuracy(labels, tf.round(pred))\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops={'acc':accuracy})\n",
    "    \n",
    "    if TRAIN:\n",
    "        global_step=tf.train.get_global_step()\n",
    "        train_op=tf.train.AdamOptimizer(0.001).minimize(loss, global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode, train_op=train_op, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\mywork\\\\NLP\\\\data_out/checkpoint/cnn/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\yuhwa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From <ipython-input-4-8c5e6255a438>:14: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.69393665, step = 0\n",
      "INFO:tensorflow:global_step/sec: 4.42152\n",
      "INFO:tensorflow:loss = 0.37082517, step = 100 (22.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.03908\n",
      "INFO:tensorflow:loss = 0.17027913, step = 200 (24.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87978\n",
      "INFO:tensorflow:loss = 0.16255169, step = 300 (25.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00617\n",
      "INFO:tensorflow:loss = 0.04067216, step = 400 (24.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00187\n",
      "INFO:tensorflow:loss = 0.0035099424, step = 500 (24.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.81581\n",
      "INFO:tensorflow:loss = 0.0033732909, step = 600 (26.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.85512\n",
      "INFO:tensorflow:loss = 0.00035881478, step = 700 (25.940 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00739\n",
      "INFO:tensorflow:loss = 0.0005521869, step = 800 (24.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00169\n",
      "INFO:tensorflow:loss = 0.0002788848, step = 900 (24.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99086\n",
      "INFO:tensorflow:loss = 0.00032334484, step = 1000 (25.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76872\n",
      "INFO:tensorflow:loss = 0.00015063962, step = 1100 (26.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.92294\n",
      "INFO:tensorflow:loss = 0.00015618064, step = 1200 (25.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.81004\n",
      "INFO:tensorflow:loss = 0.00013355925, step = 1300 (26.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.0011\n",
      "INFO:tensorflow:loss = 0.000105728046, step = 1400 (24.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.95143\n",
      "INFO:tensorflow:loss = 7.649494e-05, step = 1500 (25.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84611\n",
      "INFO:tensorflow:loss = 0.0001009212, step = 1600 (25.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76067\n",
      "INFO:tensorflow:loss = 4.723051e-05, step = 1700 (26.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00297\n",
      "INFO:tensorflow:loss = 4.32623e-05, step = 1800 (24.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.9552\n",
      "INFO:tensorflow:loss = 6.0423423e-05, step = 1900 (25.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76153\n",
      "INFO:tensorflow:loss = 4.937013e-05, step = 2000 (26.587 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.63312\n",
      "INFO:tensorflow:loss = 3.3749737e-05, step = 2100 (27.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00009\n",
      "INFO:tensorflow:loss = 4.4477136e-05, step = 2200 (24.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84144\n",
      "INFO:tensorflow:loss = 2.1594366e-05, step = 2300 (26.032 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2351...\n",
      "INFO:tensorflow:Saving checkpoints for 2351 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2351...\n",
      "INFO:tensorflow:global_step/sec: 3.65007\n",
      "INFO:tensorflow:loss = 2.4185123e-05, step = 2400 (27.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.75354\n",
      "INFO:tensorflow:loss = 2.972272e-05, step = 2500 (26.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.96708\n",
      "INFO:tensorflow:loss = 1.890152e-05, step = 2600 (25.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.9503\n",
      "INFO:tensorflow:loss = 2.1013364e-05, step = 2700 (25.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76099\n",
      "INFO:tensorflow:loss = 2.0629126e-05, step = 2800 (26.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87228\n",
      "INFO:tensorflow:loss = 2.2186507e-05, step = 2900 (25.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98202\n",
      "INFO:tensorflow:loss = 1.3401799e-05, step = 3000 (25.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98897\n",
      "INFO:tensorflow:loss = 1.6172402e-05, step = 3100 (25.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.74892\n",
      "INFO:tensorflow:loss = 1.2965234e-05, step = 3200 (26.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87999\n",
      "INFO:tensorflow:loss = 1.678188e-05, step = 3300 (25.774 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98468\n",
      "INFO:tensorflow:loss = 1.669906e-05, step = 3400 (25.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.88481\n",
      "INFO:tensorflow:loss = 1.4228862e-05, step = 3500 (25.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.24443\n",
      "INFO:tensorflow:loss = 1.3318987e-05, step = 3600 (30.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.70519\n",
      "INFO:tensorflow:loss = 1.23121945e-05, step = 3700 (26.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.02507\n",
      "INFO:tensorflow:loss = 6.298841e-06, step = 3800 (24.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94397\n",
      "INFO:tensorflow:loss = 6.818843e-06, step = 3900 (25.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.82773\n",
      "INFO:tensorflow:loss = 8.220591e-06, step = 4000 (26.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.47706\n",
      "INFO:tensorflow:loss = 6.550841e-06, step = 4100 (28.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.70615\n",
      "INFO:tensorflow:loss = 4.0465975e-06, step = 4200 (26.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.83685\n",
      "INFO:tensorflow:loss = 6.385788e-06, step = 4300 (26.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.68284\n",
      "INFO:tensorflow:loss = 6.507734e-06, step = 4400 (27.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.85692\n",
      "INFO:tensorflow:loss = 4.11058e-06, step = 4500 (25.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.01187\n",
      "INFO:tensorflow:loss = 4.645629e-06, step = 4600 (24.924 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4634...\n",
      "INFO:tensorflow:Saving checkpoints for 4634 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4634...\n",
      "INFO:tensorflow:global_step/sec: 3.88073\n",
      "INFO:tensorflow:loss = 6.7054925e-06, step = 4700 (25.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.68402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 3.5924172e-06, step = 4800 (27.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.95905\n",
      "INFO:tensorflow:loss = 3.493723e-06, step = 4900 (25.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98683\n",
      "INFO:tensorflow:loss = 3.9908728e-06, step = 5000 (25.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.9528\n",
      "INFO:tensorflow:loss = 3.2160276e-06, step = 5100 (25.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.65866\n",
      "INFO:tensorflow:loss = 3.2543455e-06, step = 5200 (27.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.91883\n",
      "INFO:tensorflow:loss = 2.6232224e-06, step = 5300 (25.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.01138\n",
      "INFO:tensorflow:loss = 2.4389801e-06, step = 5400 (24.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.0121\n",
      "INFO:tensorflow:loss = 2.5648562e-06, step = 5500 (24.932 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.50942\n",
      "INFO:tensorflow:loss = 1.8401024e-06, step = 5600 (28.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.73642\n",
      "INFO:tensorflow:loss = 1.8400646e-06, step = 5700 (26.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.96587\n",
      "INFO:tensorflow:loss = 1.7115456e-06, step = 5800 (25.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98283\n",
      "INFO:tensorflow:loss = 1.098832e-06, step = 5900 (25.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.82285\n",
      "INFO:tensorflow:loss = 1.8691718e-06, step = 6000 (26.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.72772\n",
      "INFO:tensorflow:loss = 3.03718e-06, step = 6100 (26.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98897\n",
      "INFO:tensorflow:loss = 1.5015396e-06, step = 6200 (25.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.02394\n",
      "INFO:tensorflow:loss = 1.6901641e-06, step = 6300 (24.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99093\n",
      "INFO:tensorflow:loss = 1.4213797e-06, step = 6400 (25.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.66689\n",
      "INFO:tensorflow:loss = 1.2156603e-06, step = 6500 (27.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.82373\n",
      "INFO:tensorflow:loss = 6.814039e-07, step = 6600 (26.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.90006\n",
      "INFO:tensorflow:loss = 9.721609e-07, step = 6700 (25.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.90559\n",
      "INFO:tensorflow:loss = 9.042564e-07, step = 6800 (25.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.68337\n",
      "INFO:tensorflow:loss = 9.973038e-07, step = 6900 (27.149 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6948...\n",
      "INFO:tensorflow:Saving checkpoints for 6948 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6948...\n",
      "INFO:tensorflow:global_step/sec: 3.9409\n",
      "INFO:tensorflow:loss = 1.1793948e-06, step = 7000 (25.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84861\n",
      "INFO:tensorflow:loss = 8.2626923e-07, step = 7100 (25.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.75284\n",
      "INFO:tensorflow:loss = 4.227452e-07, step = 7200 (26.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.86317\n",
      "INFO:tensorflow:loss = 5.8537574e-07, step = 7300 (25.884 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.97556\n",
      "INFO:tensorflow:loss = 7.200462e-07, step = 7400 (25.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99811\n",
      "INFO:tensorflow:loss = 6.9798773e-07, step = 7500 (25.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.72842\n",
      "INFO:tensorflow:loss = 6.0628054e-07, step = 7600 (26.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.82091\n",
      "INFO:tensorflow:loss = 8.728829e-07, step = 7700 (26.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99925\n",
      "INFO:tensorflow:loss = 7.386784e-07, step = 7800 (25.005 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.02261\n",
      "INFO:tensorflow:loss = 6.3142625e-07, step = 7900 (24.858 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.74982\n",
      "INFO:tensorflow:loss = 6.16866e-07, step = 8000 (26.676 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76701\n",
      "INFO:tensorflow:loss = 5.9281183e-07, step = 8100 (26.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.02075\n",
      "INFO:tensorflow:loss = 3.2566658e-07, step = 8200 (24.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99832\n",
      "INFO:tensorflow:loss = 4.2475818e-07, step = 8300 (25.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84835\n",
      "INFO:tensorflow:loss = 3.197904e-07, step = 8400 (25.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.73319\n",
      "INFO:tensorflow:loss = 3.167609e-07, step = 8500 (26.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99106\n",
      "INFO:tensorflow:loss = 3.4002733e-07, step = 8600 (25.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00711\n",
      "INFO:tensorflow:loss = 2.6363114e-07, step = 8700 (24.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.80519\n",
      "INFO:tensorflow:loss = 3.2943302e-07, step = 8800 (26.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.80025\n",
      "INFO:tensorflow:loss = 3.1345348e-07, step = 8900 (26.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.97789\n",
      "INFO:tensorflow:loss = 3.3886505e-07, step = 9000 (25.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.95635\n",
      "INFO:tensorflow:loss = 2.8205497e-07, step = 9100 (25.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.32147\n",
      "INFO:tensorflow:loss = 2.036965e-07, step = 9200 (30.108 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9259...\n",
      "INFO:tensorflow:Saving checkpoints for 9259 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9259...\n",
      "INFO:tensorflow:global_step/sec: 3.68825\n",
      "INFO:tensorflow:loss = 3.2449356e-07, step = 9300 (27.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94033\n",
      "INFO:tensorflow:loss = 1.539811e-07, step = 9400 (25.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76154\n",
      "INFO:tensorflow:loss = 1.4191414e-07, step = 9500 (26.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.65188\n",
      "INFO:tensorflow:loss = 1.6849708e-07, step = 9600 (27.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.64587\n",
      "INFO:tensorflow:loss = 1.8782265e-07, step = 9700 (27.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87623\n",
      "INFO:tensorflow:loss = 1.8424109e-07, step = 9800 (25.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.92306\n",
      "INFO:tensorflow:loss = 1.9482204e-07, step = 9900 (25.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84806\n",
      "INFO:tensorflow:loss = 1.626876e-07, step = 10000 (25.995 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.60768\n",
      "INFO:tensorflow:loss = 1.415494e-07, step = 10100 (27.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.86786\n",
      "INFO:tensorflow:loss = 1.6464593e-07, step = 10200 (25.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99078\n",
      "INFO:tensorflow:loss = 1.3717423e-07, step = 10300 (25.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.96202\n",
      "INFO:tensorflow:loss = 1.3175884e-07, step = 10400 (25.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.59171\n",
      "INFO:tensorflow:loss = 9.321323e-08, step = 10500 (27.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.888\n",
      "INFO:tensorflow:loss = 1.3379488e-07, step = 10600 (25.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.03025\n",
      "INFO:tensorflow:loss = 7.53905e-08, step = 10700 (24.811 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.99421\n",
      "INFO:tensorflow:loss = 7.095079e-08, step = 10800 (25.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.76259\n",
      "INFO:tensorflow:loss = 7.346471e-08, step = 10900 (26.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.85412\n",
      "INFO:tensorflow:loss = 1.2068176e-07, step = 11000 (25.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98675\n",
      "INFO:tensorflow:loss = 7.817641e-08, step = 11100 (25.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87271\n",
      "INFO:tensorflow:loss = 8.519122e-08, step = 11200 (25.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.62473\n",
      "INFO:tensorflow:loss = 6.457101e-08, step = 11300 (27.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.92049\n",
      "INFO:tensorflow:loss = 5.2319578e-08, step = 11400 (25.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.85323\n",
      "INFO:tensorflow:loss = 7.5267444e-08, step = 11500 (25.953 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11555...\n",
      "INFO:tensorflow:Saving checkpoints for 11555 into C:\\mywork\\NLP\\data_out/checkpoint/cnn/model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Users\\yuhwa\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11555...\n",
      "INFO:tensorflow:global_step/sec: 3.51587\n",
      "INFO:tensorflow:loss = 6.721899e-08, step = 11600 (28.441 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 3.56344\n",
      "INFO:tensorflow:loss = 6.159111e-08, step = 11700 (28.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.89008\n",
      "INFO:tensorflow:loss = 7.37486e-08, step = 11800 (25.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.98119\n",
      "INFO:tensorflow:loss = 6.6259375e-08, step = 11900 (25.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00186\n",
      "INFO:tensorflow:loss = 3.6151775e-08, step = 12000 (24.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.73222\n",
      "INFO:tensorflow:loss = 5.6634107e-08, step = 12100 (26.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.57525\n",
      "INFO:tensorflow:loss = 5.4141474e-08, step = 12200 (27.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.77562\n",
      "INFO:tensorflow:loss = 3.899367e-08, step = 12300 (26.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.86838\n",
      "INFO:tensorflow:loss = 4.851951e-08, step = 12400 (25.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.93735\n",
      "INFO:tensorflow:loss = 2.9146939e-08, step = 12500 (25.399 sec)\n"
     ]
    }
   ],
   "source": [
    "model_dir=os.path.join(os.getcwd(),\"data_out/checkpoint/cnn/\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Estimator 객체 생성\n",
    "cnn_est=tf.estimator.Estimator(model_fn, model_dir=model_dir)\n",
    "# 학습하기\n",
    "cnn_est.train(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가하기\n",
    "enn_est.evaluate(eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH='./data_in/'\n",
    "DATA_OUT_PATH='./data_out/'\n",
    "TEST_INPUT_DATA='test_input.npy'\n",
    "TEST_ID_DATA='test_id.npy'\n",
    "\n",
    "test_input_data=np.load(open(DATA_IN_PATH+TEST_INPUT_DATA,'rb'))\n",
    "ids=np.load(open(DATA_IN_PATH+TEST_ID_DATA,'rb'))\n",
    "\n",
    "print(eval_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
